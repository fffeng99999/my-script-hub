
# 论文标题

Learning Syntax Without Planting Trees: Understanding When and Why Transformers Generalize Hierarchically

# 研究动机

尽管Transformer模型在各种语言任务中表现卓越,但他们是否能自发学到语言的层次结构,一直是一个开放问题

语言是层次性的,而transformer是扁平结构,人类语言具有树状语法结构(如短语结构,依存结构),传统认为学习语法规则需要显式建树,然而transformer不使用任何显式的语法结构或监督,但在许多任务中表现极好,这也引发了一个关键问题:它是否隐式地学会了语言地层级结构

已有实验现象支持泛化能力,但缺乏系统解释:早期工作发现语言模型在某些句法泛化任务上表现得像懂语法,但这些工作大多基于个别probe或对比实验,无法解释何时,为何模型会泛化,或在哪种训练环境下形成层级结构偏好

是否需要树状结构才能获得句法泛化:有一种观点认为,如果没有显式结构监督或inductive bias模型将更倾向于学习表层线性关系,因此作者希望解答:是否仅仅靠语言建模目标(例如LM loss).就能诱导出层级泛化,以及这种泛化得前提条件是什么

泛化行为背后是否存在可解释得偏好:作者不仅关心模型是否能泛化,还关心其泛化行为是否有内部结构性可解释性,因此,他们引入贝叶斯建模视角,从而解释学习偏好出发,探索哪种规则更简洁,从而更容易被学习

# 核心贡献

提出结构最小化框架分析Transformer的句法泛化:作者系统构造出了一系列可以区分层次泛化与线性泛化的任务数据集,设计出一个结构最小化分析框架,通过分析不同类型的结构规则(如线性和树形)的解释简洁性与模型输出之间的偏好关系

实证发现Transformer存在显著的层级泛化行为,在多个语法结构对比任务中,作者发现训练不显式监督任何结构,但训练后的Transformer表现出与人类语言规则一致的句法泛化行为,即偏向于选择符合树状结构而非表层顺序规则

通过剪枝实验揭示Transformer中的子网络负责不同的泛化规则:作者对模型参数进行剪枝分析,发现:不同参数子集支持不同类型的泛化,即Transformer内部存在多个候选规则的表示子网络,模型通过训练逐渐倾向于激活支持层次泛化的子网络

引入贝叶斯建模解释为何模型偏好层级规则:作者构建贝叶斯后验推理模型,衡量各种候选规则在解释训练样本时的复杂度,实验表明:层次规则通常比线性规则更简单,更通用,具有更高的先验概率,Transformer之所以偏好层级规则,是因为他们在训练语料上具有更低的解释成本,即最小结构代价

# 方法贡献

# 实验现象

# 有待解决问题

# 适用领域

# 是否引用