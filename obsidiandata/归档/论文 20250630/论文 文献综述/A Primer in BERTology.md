
# 论文标题

A Primer in BERTology

# 研究动机

作者指出,从BERT发布以来,他在多个NLP任务中表现十分出色,成为必备基线模型,但是我们虽然知道BERT有效但我们还不知道它为什么如此有效,这也限制了我们更好的来结构化控制和理解它理论的有效性,作者认为Transformer缺乏认知动机,很难解释,与传统的CNN相比,它缺乏明显的认知结构对应,其性能不能与直观相对应,再加上BERT的规模巨大,使得如果要细节控制每一个模块来分析了解每一部分的作用十分困难而且成本极高,作者再次说,虽然一年多来,已经有大量学者尝试从Transformer的各种技术细节出发来分析BERT,但是这些工作十分分散,没有统一性的框架性综述,他们之间的矛盾也没有被梳理解释,作者想要通过自己的这种梳理来解释BERT成功背后的机制,结构化信息流与表示层次性,为未来关于Transformer的研究提供理解基础.

# 核心贡献

系统性综述BERT得结构认知与机制,Rogers等人通过结构性分类框架将现有得研究分为三类,分别对应BERT得1.表达能力,2.表达位置,3.是否被使用,他们围绕这三个问题,采用归纳得方法1.表达能力归纳方法:收集各类probing task得实验,如POS,chunking,SRL,NER等任务得探针分类器精度,统计MLM下BERT对句法一致性,语义填空,常识推理得表现,结论是句法信息存在但并不总被attention明确编码,语义信息存在于整个模型中,表现为上下文敏感分布,常识知识以典型经验形式存在,但缺乏组合性推理.2.表达位置归纳方式,汇总了大量关于layer-wise probing得实验,如不同层在不同任务下得表现曲线,分析了attention head得空间分布以及语法功能偏向,结果为,底层偏向表层信息(字面token特征),中层承担最多可迁移结构信息(如依存结构,主谓一致).高层受任务fine-tuning强烈影响,更特定于下游任务.3.是否被使用归纳方法:梳理了包括amnesic probing, layer ablation, head pruning在内得实验设计,比较模型能表示与模型是否能用到之间得差距.结论是:模型会encode很多语言信息,但不一定在推理中使用他,部分知识为冗余表示,存在多个head或层中,推理中使用得结构往往与表现出得结构不完全一致.

三个关键研究维度,1.BERT拥有什么知识,2.这些知识被表现在模型得哪里,3.这些知识在推理中是否真正被使用.一个一个来,对于第一个问题,BERT在预训练后,到底获得了哪些语言知识,是否掌握1语法结构(如主谓一致),是否掌握了语义角色(如动宾逻辑),是否具备尝试推理能力,对应得研究方法是Probing Task(探针实验),通过在不同层嵌入训练轻量分类器(probe),判断模型是否包含指定得语言属性,例如:POS tagging(词性),Dependency depth(句法深度),SRL(语义角色标注),NLI(蕴含逻辑),对于第二个问题,所探求得问题是语言知识集中在哪些层,Attention head是否具有特定语言功能,是否存在层级语义得功能分工,对应得研究方法是分析不同attention head得关注对象,看是否1对句法结构,实体,句界等有偏好,分层评估BERT各层表示得任务性能,观察最富有语言结构得层在哪,实验结构:中层(6-9)通常有最多得句法信息,attention head中存在冗余模式,如大量关注SEP,CLS,标点,特定head可用于执行如coreference resolution等任务.第三个问题,所探求得问题,哪些信息对模型得预测真的起了决定性作用,是哪些层/head决定了输出,而不是装饰性结构,模型是不是依赖浅层启发式而不是真正得语言理解.对应得研究方法,人为忘掉某些知识,观察性能下降,去掉某些head/layer,看对任务是否有影响,分析哪些token影响预测最大

跨层视角构建分层知识地图,明确BERT得每一层在信息表征中得作用差异,建立起从底层到高层得信息流与功能分布图谱,低层(1-4层)功能侧重表层结构,词序,位置嵌入,主要发现,包含最多线性顺序信息,但语义较弱,中层(5-9层)句法结构,依存关系,主要发现,可恢复dependency tree,主谓一致能力最强,高层(10-12层),功能侧重语义抽象,任务特化,主要发现Fine-tuning时改动最大,适应任务要求

连接BERT表征结构与优化机制,目标:解释BERT得表征结构是否具有必要性和稳定性,揭示模型在剪枝,压缩,蒸馏过程中得冗余与泛化边界,构建解释性,优化机制之间得桥梁,支持实际模型部署与推理效率改进,1.剪枝(BERT得注意力冗余),对每一层得attention head进行逐个删除,结构表明绝大多数head去掉模型性能几乎不变,表明:注意力分布不是解释机制,而是优化路径上得冗余结构.在翻译任务中通过逐步剪枝不重要得head,同时评估BLEU得分变化,注意力head有选择性沉默,一些head没有明显聚焦目标,剪掉attention head并不代表删除某功能,因为信息1可能被多个head冗余表示.总体结论:注意力head中存在显著冗余,支持进一步参数压缩与替换,与信息层次性结论结合,不是所有层都重要,不是所有head都必须.2.知识蒸馏(功能保持得轻量迁移),核心发现,使用小模型mimic大模型得行为(如TinyBERT)蒸馏成功依赖于保留层次得信息流与注意力方向,在任务上进行训练时,蒸馏模型常常泛化性更好,说明中层结构得迁移是最核心得知识承载路径,结论:中间层是蒸馏得核心通道,最能压缩但不失去知识,与剪枝相反,蒸馏不是删除,而是转移+选择性保留.3.预训练变体(结构创新,结构改变与泛化能力关系),ALBERT得权重共享+embedding factorization,减少参数冗余,ELECTRA:代替MLM训练目标,提高sample efficiency,SpanBERT:在span级别编码更多上下文语义,强化中层信息,这些方法表明,改变结构并不一定破坏表现,反而可以强化结构-功能一致性,解耦注意力数量和效果是当前优化路径得关键方向

# 方法贡献

这是首篇全面综述BERT模型行为与内部机制的工作,作者对150篇研究成果进行了分类整理,覆盖范围广,系统性强:语言知识的学习与表达,模型结构局部性(embedding 层,attention head,不同层次结构),训练机制优化(预训练与微调),模型压缩与剪枝,推理与理解分析方法,作者对BERT学到了什么这一关键问题进行了细致梳理,分为句法知识,语义知识,世界知识,方法亮点:使用probing,attention可视化,mask测试等多种分析手段,从多角度解构BERT表征的语言知识结构.他们系统的分析了BERT每一层的功能划分:底层(表层特征),中层(句法特征),高层(语义分布),指出[CLS][SEP]特殊token的attention模式在微调后明显上升,意味着1这些位置可能不携带语义,而更多式模型利用位置标识,方法亮点:使用层级probing实验,注意力权重分类,迁移任务对比,建立了功能层级的经验性归纳,作者总结了多种预训练目标,结构变化及其对性能的影响,架构变量实验:通过控制变量(如层数,head数,隐藏维度)分析其对性能和迁移能力的影响,训练技巧对比:包括大batch训练,warm-start层复制训练,各种masking策略,压缩与剪枝策略对比:系统整理distillation,quantization,structured/unstructured pruning的性能和效率,方法亮点:以对比实验与性能归因为核心,尝试分析性压缩作为模型interpretability研究路径

# 实验现象

BERT学到了什么知识:句法知识,BERT表征是层次结构的而非线性序列,表现为中层token embedding可以重建句法树,部分attention head显著关注句法角色,如某些head经常从动词指向主语,但BERT无法完整从attention weight中恢复句法树结构,对无语义也能实现主谓一致预测

BERT有哪些世界与语义知识:语义与常识知识,BERT能部分区分语义角色,BERT能填空式召回部分世界知识,但BERT不能进行组合性推理,替换实体名会显著改变模型输出

模型结构与表征分布:层级结构与功能划分,低层负责词序信息,中层学习语法,高层偏向语义与任务特定表征,fine-tuning改变attention模式,使其更加关注[CLS]与[SEP],恢复fine-tuned模型低层参数对性能影响不大

训练目标与改进效果:NSP任务是否必要仍存在争议,wordPiece分词不适合处理数值信息,训练数据中结构词过频繁导致attention偏向这些token

压缩与模型剪枝相关实验:40%的attention head可直接剪除而不影响性能,大多数head只学习关注标点,而非语言信息,部分层反而在probing任务中降低性能

# 有待解决问题

# 适用领域

# 是否引用